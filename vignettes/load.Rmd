---
title: "Loading in Data"
author: "Steffi LaZerte"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Loading/Importing Data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
<a id = "top"></a>

```{r, include = F}
library(feedr)
```

This is a quick tutorial to get you started with loading in your own data. `feedr` includes several wrapper functions that can be used to load and format your data.

- [`load_raw()`](#loadraw)
- [`load_raw_web()`](#loadrawall)
- [`load_web()`](#loadweb)
- [`dl_data()`](#dldata)

These functions work with either __raw__ feeder data (downloaded directly from the feeders) or __web__ feeder data downloaded from the birdmoves websites (either by hand, from <http://gaia.tru.ca/birdMOVES/datadownload.html>, or with the `dl_data()` function.


## A note about file structure

It's important to remember that when specifying file locations, you must either specify a complete file id (e.g. /home/steffi/Desktop/data.csv) __or__ an appropriate relative file location.

Also, remember that file locations are relative to where R's working directory is, and this is not necessarily the same place as the R script with which you are working.

If you are using RStudio, it is highly recommended that you specify an RStudio project in the directory which holds your scripts. This way, anytime you open the file, the working directly is automatically set to your script directly.

Otherwise you should probably use Session > Set Working Directory > To Source File Location (if you're using RStudio).

__This tutorial assumes that your data is stored in a folder called "Data" which is in turn stored in your R scripts folder.__

<a id="loadraw"></a>

## `load_raw()`

This loads and formats a raw data file downloaded directly from feeder RFID readers.

```{r echo = FALSE}
all.files <- list.files(system.file("extdata", "raw", "exp1", package = "feedr"), full.names = T)
r1 <- load_raw(all.files[1])
```

```{r eval = FALSE}
r1 <- load_raw("./Data/exp1/GR10DATA_2015_12_09.TXT")
head(r1)
```

```{r echo = FALSE}
head(r1)
```

Note that the feeder_id is taken from the file name. This is done by matching an expected pattern against the actual file name.

The default pattern matches GR or GPR followed by 1 or 2 digits. If you need to specify a different pattern you can do so:

```{r eval = FALSE}
r1 <- load_raw("./Data/exp1/Feeder_10_2015_12_09.TXT", feeder_pattern = "Feeder_[0-9]{2}")
head(r1)
```

For more information on how to write patterns, see documentation for "Regular Expressions" (e.g. <http://www.regular-expressions.info/tutorial.html>)

<a id="loadrawall"></a>

## `load_raw_all()`

The function `load_raw_all()` is a wrapper function which will automatically load and combine data contained in several different files in a single folder, or in a nested series of folders. Other files can be present, but all feeder data files must be identifiable by a pattern in the file name.

In this example our data files are stored in a folder called `raw` and there are several sets of data, each corresponding to an individual experiment which are then stored in their own folder called `exp1`, `exp2`, etc. Feeder data files are identifiable by the characters 'DATA' present in the name (as in the above example), which is the default.

```{r eval = FALSE}
r <- load_raw_all(r_dir = "./Data/raw")
head(r)
```

```{r echo = FALSE}
r <- load_raw_all(r_dir = list.files(system.file("extdata", package = "feedr"), pattern = "raw", full.names = T))
head(r)
```

If your feeder files didn't have a identiifable label, but were the only csv files in the folders, you could use:
```{r eval = FALSE}
r <- load_raw_all(r_dir = "./Data/raw", pattern = ".csv")
```

However, in this example we have several different experiments, which we'll probably want to identify in our data. This is where the `extra` arguments come in.

In our example, each experiment is stored in its own folder (exp1 and exp2). Therefore we can tell our function to identify those patterns (`extra_pattern`) and store the values in an extra column (`extra_name`):

```{r eval = FALSE}
r <- load_raw_all(r_dir = "./Data/raw", extra_pattern = "exp[1-2]{1}", extra_name = "experiment")
```

```{r echo = FALSE}
r <- load_raw_all(r_dir = list.files(system.file("extdata", package = "feedr"), pattern = "raw", full.names = T), extra_pattern = "exp[1-2]{1}", extra_name = "experiment")
head(r)
```

"exp[1-2]{1}" matches the exact characters "exp" followed by either a 1 or a 2 of which there is exactly 1.

We can also merge in some extra values for use later (visualizations, etc.)

```{r echo = FALSE}
f.index <- read.csv(system.file("extdata", "feeder_index.csv", package = "feedr"))
f.index
```

```{r eval = FALSE}
f.index <- read.csv("./Data/feeder_index.csv")
f.index
```

```{r}
r <- merge(r, f.index, by = c("experiment", "feeder_id"))
head(r)
```

Because here, the feeder units were reused for different experiments, some feeders have the same id, but a different lat/lon. This will create problems later on, so let's create unique feeder_id names:

```{r}
r$feeder_id <- paste(r$experiment, r$feeder_id, sep = "-")
head(r)
```

<a id="loadweb"></a>

## `load_web()`

```{r, echo = FALSE}
r <- load_web(system.file("extdata", "load_web.csv", package = "feedr"))
```

You can go to <http://gaia.tru.ca/birdMOVES/datadownload.html> and download a csv file of data from the BirdMoves website. To load and format this data for use with the feedr package, run:

```{r, eval = FALSE}
r <- load_web("./Data/load_web.csv")
head(r)
```
```{r, echo = FALSE}
head(r)
```

The default timezone is "America/Vancouver", therefore, if your data is from a different time zone, you need to specify that manually. Make sure you use a timezone name from the output of OlsonNames(). For example:

```{r, eval = FALSE}
r <- load_web("./Data/load_web.csv", tz = "America/Costa_Rica")
r$time[1]
head(r)
```

```{r, echo = FALSE}
r <- load_web(system.file("extdata", "load_web.csv", package = "feedr"), tz = "America/Costa_Rica")
r$time[1]
head(r)
```

__Note:__ This doesn't _convert_ the time from one zone to another, it merely _assigns_ the timezone. Make sure this matches the timezone of the original data download.

<a id="dldata"></a>

## `dl_data()`

This is likely the easiest way to get data (provided the data you're interested in is hosted on the BirdMoves website). This function requests data from the BirdMoves website and formats it for use with the feedr transformation functions.

If you don't specify anything, all data will be downloaded for the default site (Kamloops) and the default extra columns (loc and species) with the default timezone (America/Vancouver). See ?dl_data for more details.

```{r, echo = FALSE}
r <- dl_data(end = "2015-09-06")
head(r)
```

```{r, eval = FALSE}
r <- dl_data()
head(r)
```

You can specify start and end times:

```{r}
r <- dl_data(start = "2015-10-01", end = "2015-10-02")
head(r)
```

```{r}
r <- dl_data(start = "2015-10-01 09:00:00", end = "2015-10-02")
head(r)
```

You can also specify only a start or an end, all data up to or after that point will be grabbed:

```{r}
r <- dl_data(end = "2015-09-06")
head(r)
```

Extra bird or feeder related details (?dl_data for more):

```{r}
r <- dl_data(end = "2015-09-06", feeder_details = c("loc","site_name"), bird_details = c("species", "age", "sex"))
head(r)
```

Different Sites:
```{r}
r <- dl_data(end = "2013-02-14 09:00:00", site = "Costa Rica", feeder_details = c("loc","site_name"))
head(r)
```
--------------------------
Back to [top](#top)  
Go back to [main document](feedr.html) | Continue with [housekeeping](housekeeping.html)

